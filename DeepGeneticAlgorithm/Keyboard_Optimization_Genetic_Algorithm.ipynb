{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/MathMayhem/4644_final/blob/main/DeepGeneticAlgorithm/Keyboard_Optimization_Genetic_Algorithm.ipynb\" target=\"_parent\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkRamzt5rpLX"
      },
      "outputs": [],
      "source": [
        "# Setup the API Server\n",
        "\n",
        "# Installing Dependences\n",
        "!sudo apt-get update -qq\n",
        "!sudo apt-get install -y build-essential libmicrohttpd-dev libjson-c-dev xz-utils\n",
        "!pip install requests -q\n",
        "\n",
        "# Installing API Server\n",
        "!wget https://github.com/RusDoomer/SVOBODA/archive/refs/tags/v0.1.tar.gz -O svoboda.tar.gz -q\n",
        "!tar -xzf svoboda.tar.gz\n",
        "!cd SVOBODA-0.1 && make\n",
        "!wget https://colemak.com/pub/corpus/iweb-corpus-samples-cleaned.txt.xz -q\n",
        "!unxz iweb-corpus-samples-cleaned.txt.xz\n",
        "!mv iweb-corpus-samples-cleaned.txt SVOBODA-0.1/data/english/corpora/shai.txt\n",
        "\n",
        "# Starting API Server\n",
        "import subprocess\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import signal\n",
        "\n",
        "# --- Configuration ---\n",
        "server_directory = 'SVOBODA-0.1'\n",
        "executable_name = './svoboda'\n",
        "api_url = \"http://localhost:8888/\"\n",
        "startup_timeout_seconds = 60\n",
        "\n",
        "# --- Process Handling ---\n",
        "server_process = None\n",
        "\n",
        "if not os.path.exists(os.path.join(server_directory, executable_name)):\n",
        "    print(\"Error: Server executable not found. Please run the setup cell first.\")\n",
        "else:\n",
        "    print(\"Starting C server in the background...\")\n",
        "    # Launch the server in the background\n",
        "    server_process = subprocess.Popen(\n",
        "        [executable_name],\n",
        "        cwd=server_directory,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        text=True\n",
        "    )\n",
        "\n",
        "    # --- Verification Loop ---\n",
        "    server_ready = False\n",
        "    start_time = time.time()\n",
        "    while time.time() - start_time < startup_timeout_seconds:\n",
        "        # Check if the process has already terminated\n",
        "        if server_process.poll() is not None:\n",
        "            print(f\"Error: Server process terminated unexpectedly with exit code {server_process.poll()}.\")\n",
        "            # Print stderr for debugging\n",
        "            for line in server_process.stderr.readlines():\n",
        "                print(f\"[SERVER_STDERR] {line.strip()}\")\n",
        "            break\n",
        "\n",
        "        # Attempt to connect\n",
        "        try:\n",
        "            response = requests.get(api_url, timeout=1)\n",
        "            print(f\"\\nSuccess: Server is responsive at {api_url}.\")\n",
        "            server_ready = True\n",
        "            break\n",
        "        except requests.exceptions.ConnectionError:\n",
        "            print(\".\", end=\"\")\n",
        "            time.sleep(1)\n",
        "\n",
        "    if not server_ready and server_process.poll() is None:\n",
        "        print(\"\\nError: Server did not become responsive within the timeout period.\")\n",
        "        print(\"The process is still running but may be stuck. Terminating.\")\n",
        "        server_process.terminate()\n",
        "    elif server_ready:\n",
        "        print(f\"Server is running with PID: {server_process.pid}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "0bO_XIgPp9QT"
      },
      "outputs": [],
      "source": [
        "# Required Imports for the Neural Network\n",
        "\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "import time\n",
        "import pickle\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers, optimizers\n",
        "\n",
        "# The symbols whose keyboard positions we are optimizing\n",
        "# Layouts will be represented as lists of indices from this symbol set\n",
        "symbols = \"abcdefghijklmnopqrstuvwxyz;,./\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75_N8rgisWEn",
        "outputId": "8e61e95c-b96d-404a-ecd1-1a8ee10d1c82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount your drive to use our data files or generate your own\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ziieJwOFsuLK"
      },
      "outputs": [],
      "source": [
        "# The Basic Unit of our Neural Network. This defines a custom Fully Connected Layer with a Leaky ReLU activation function and skip connection around the entire layer.\n",
        "class CustomLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    A custom Keras layer that combines a Dense layer, Leaky ReLU activation,\n",
        "    and a conditional skip connection.\n",
        "\n",
        "    The skip connection adds the original input to the output of the\n",
        "    Dense -> Leaky ReLU sequence ONLY if the last dimension of the input\n",
        "    matches the number of units in the Dense layer.\n",
        "    \"\"\"\n",
        "    def __init__(self, units, negative_slope=0.5, l2_reg=0.0, **kwargs):\n",
        "        \"\"\"\n",
        "        Initializes the custom layer.\n",
        "\n",
        "        Args:\n",
        "            units (int): The number of output units for the Dense layer.\n",
        "            alpha (float): The negative slope coefficient for the Leaky ReLU activation.\n",
        "            **kwargs: Additional keyword arguments to pass to the base Layer class.\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.negative_slope = negative_slope\n",
        "        self.l2_reg = l2_reg\n",
        "\n",
        "        kernel_regularizer = regularizers.l2(self.l2_reg)\n",
        "\n",
        "\n",
        "        # Initialize the Dense layer and Leaky ReLU activation\n",
        "        # These will create their weights when first called (or in build if explicitly built)\n",
        "        self.dense_layer = layers.Dense(self.units, kernel_regularizer=kernel_regularizer, name=\"dense_part\")\n",
        "        self.leaky_relu_activation = layers.LeakyReLU(negative_slope=self.negative_slope, name=\"leaky_relu_part\")\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"\n",
        "        Builds the layer's weights. This method is called automatically\n",
        "        the first time the layer is run.\n",
        "\n",
        "        Args:\n",
        "            input_shape (tf.TensorShape): The shape of the input tensor.\n",
        "                                          Typically (batch_size, ..., input_dim).\n",
        "        \"\"\"\n",
        "        # The dense layer's weights are implicitly built when it's called\n",
        "        # with an input of known shape. We explicitly build it here to\n",
        "        # ensure its weights are created before the first call, which can\n",
        "        # be useful for inspection or if the layer is part of a larger model\n",
        "        # that needs to know all its weights upfront.\n",
        "        self.dense_layer.build(input_shape)\n",
        "\n",
        "        # Determine if a skip connection is possible based on input and output dimensions.\n",
        "        # The skip connection adds the original input to the processed output.\n",
        "        # For this to work, the last dimension of the input must match the number of units.\n",
        "        self.can_skip_connect = (input_shape[-1] == self.units)\n",
        "        if not self.can_skip_connect:\n",
        "            print(f\"Warning: Skip connection not possible for layer '{self.name}'.\")\n",
        "            print(f\"Input last dimension ({input_shape[-1]}) does not match Dense units ({self.units}).\")\n",
        "            print(\"The layer will function as a standard Dense + Leaky ReLU.\")\n",
        "\n",
        "        super().build(input_shape) # Call the base class's build method\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Defines the forward pass logic of the layer.\n",
        "\n",
        "        Args:\n",
        "            inputs (tf.Tensor): The input tensor to the layer.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: The output tensor after applying Dense, Leaky ReLU,\n",
        "                       and the conditional skip connection.\n",
        "        \"\"\"\n",
        "        # Step 1: Pass through the Dense layer\n",
        "        dense_output = self.dense_layer(inputs)\n",
        "\n",
        "        # Step 2: Apply Leaky ReLU activation\n",
        "        activated_output = self.leaky_relu_activation(dense_output)\n",
        "\n",
        "        # Step 3: Implement the conditional skip connection\n",
        "        # We check the actual shape of the `inputs` tensor at call time.\n",
        "        # Note: input_shape from build might have None for batch size,\n",
        "        # but inputs.shape will have the concrete batch size.\n",
        "        # We only care about the feature dimension (last dimension).\n",
        "        if inputs.shape[-1] == self.units:\n",
        "            # If dimensions match, add the original input to the activated output\n",
        "            output = activated_output + inputs\n",
        "            # print(f\"Info: Skip connection applied for layer '{self.name}'.\")\n",
        "        else:\n",
        "            # If dimensions don't match, no skip connection is applied\n",
        "            output = activated_output\n",
        "            # The warning about skip connection not being possible is already printed in build,\n",
        "            # but we can add a runtime message here if needed for debugging.\n",
        "            # print(f\"Info: Skip connection NOT applied for layer '{self.name}' due to dimension mismatch.\")\n",
        "\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Returns the serializable configuration of the layer.\n",
        "        This is important for saving and loading models that use custom layers.\n",
        "        \"\"\"\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"units\": self.units,\n",
        "            \"negative_slope\": self.negative_slope,\n",
        "            \"l2_reg\": self.l2_reg\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MDptl88cqPDP"
      },
      "outputs": [],
      "source": [
        "# Genetic Algorithm Methods\n",
        "\n",
        "def crossover(a, b, n):\n",
        "    c = [None for i in range(n)]\n",
        "    while any(s == None for s in c):\n",
        "        parent_choice = random.choice(['a', 'b'])\n",
        "        if parent_choice == 'a':\n",
        "            p1 = a\n",
        "            p2 = b\n",
        "        else:\n",
        "            p1 = b\n",
        "            p2 = a\n",
        "\n",
        "        starting_key = random.randint(0, n - 1)\n",
        "        while c[starting_key] != None:\n",
        "            starting_key = random.randint(0, n - 1)\n",
        "\n",
        "        c[starting_key] = p1[starting_key]\n",
        "        current_key = p2.index(p1[starting_key])\n",
        "        while current_key != starting_key:\n",
        "            c[current_key] = p1[current_key]\n",
        "            current_key = p2.index(p1[current_key])\n",
        "\n",
        "    return c\n",
        "\n",
        "\n",
        "def mutate(a, max_swaps, n):\n",
        "    b = copy.deepcopy(a)\n",
        "\n",
        "    num_swaps = random.randint(0, max_swaps)\n",
        "    for i in range(num_swaps):\n",
        "        key_1 = random.randint(0, n - 1)\n",
        "        key_2 = random.randint(0, n - 1)\n",
        "        b[key_1], b[key_2] = b[key_2], b[key_1]\n",
        "\n",
        "    return b\n",
        "\n",
        "# Calls the API Server to evaluate a batch of layouts which utilize the provided string of symbols\n",
        "# If metric weights is set to None, then this function will return each of the five individual metrics for each of the input layouts\n",
        "# Otherwise, it will return the weighted sum of these metrics using the provided metric weights\n",
        "def true_evaluation(batch, metric_weights, symbols):\n",
        "  layouts = []\n",
        "  for a in batch:\n",
        "    layouts.append(\"\")\n",
        "    for index in a:\n",
        "      layouts[-1] += symbols[index]\n",
        "\n",
        "  api_url = \"http://localhost:8888/\"\n",
        "\n",
        "  payload = [{\n",
        "    \"layout\": layout,\n",
        "    \"weights\":  {\"sfb\": 0.0, \"sfs\": 0.0, \"lsb\": 0.0, \"alt\": 0.0, \"rolls\": 0.0} if metric_weights == None else metric_weights\n",
        "  } for layout in layouts]\n",
        "\n",
        "  try:\n",
        "    response = requests.post(api_url, json=payload)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "      print(f\"Error: Server responded with status code {response.status_code}\")\n",
        "      print(\"Response text:\", response.text)\n",
        "    else:\n",
        "      if metric_weights == None:\n",
        "        return [[r[\"stat_values\"][\"sfb\"], r[\"stat_values\"][\"sfs\"], r[\"stat_values\"][\"lsb\"], r[\"stat_values\"][\"alt\"], r[\"stat_values\"][\"rolls\"]] for r in response.json()]\n",
        "      else:\n",
        "        return [r[\"score\"] for r in response.json()]\n",
        "\n",
        "  except requests.exceptions.ConnectionError as e:\n",
        "    print(\"Connection Error: Could not connect to the C server.\")\n",
        "    print(\"Please ensure the server is running correctly from the previous cell.\")\n",
        "\n",
        "\n",
        "# Similar to MKLOGA genetic algorithm, but with some small design differences and no fine-tuning of the model\n",
        "# Note: copy rate should be at least the crossover cutoff and the random rate should be at most the pop minus the copy rate\n",
        "def evolve(pop, epochs, random_rate, copy_rate, evaluation_rate, crossover_cutoff, mutation_rate, delete_duplicates, mode, model, metric_weights, symbols):\n",
        "  w = np.array([[metric_weights[\"sfb\"]], [metric_weights[\"sfs\"]], [metric_weights[\"lsb\"]], [metric_weights[\"alt\"]], [metric_weights[\"rolls\"]]])\n",
        "  n = len(symbols)\n",
        "\n",
        "  # Layouts in the generation are split between those whose scores have been estimated by the model, those who have received a true evaluation, and those with neither of these\n",
        "  # This makes the method more efficient by avoiding repeated evaluations\n",
        "  current_generation = {\"no scores\": [], \"estimated scores\": [], \"true scores\": []}\n",
        "\n",
        "  # The first generation is created randomly\n",
        "  a = [i for i in range(n)]\n",
        "  for i in range(pop):\n",
        "    random.shuffle(a)\n",
        "    current_generation[\"no scores\"].append(copy.deepcopy(a))\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    ## ESTIMATED/TRUE EVALUATIONS PERFORMED ##\n",
        "\n",
        "    if mode == 1:\n",
        "      # In this mode the passed in model is ignored and every layout is given a true evaluation\n",
        "      # The crossover cutoff controls how many of the top layouts given true evaluations are used in the crossover/mutation phase\n",
        "      # Since layouts past this cutoff will no longer affect the algorithm, they are deleted at this stage\n",
        "      new_scores = true_evaluation(current_generation[\"no scores\"], metric_weights, symbols)\n",
        "      current_generation[\"true scores\"] += list(zip(current_generation[\"no scores\"], new_scores))\n",
        "      current_generation[\"no scores\"] = []\n",
        "      current_generation[\"true scores\"] = sorted(current_generation[\"true scores\"], key = lambda x : x[1], reverse = True)[:crossover_cutoff]\n",
        "    elif mode == 2:\n",
        "      # In this mode true evaluations are not used and the model is treated as the ground truth\n",
        "      new_scores = list(np.matmul(model(np.array(current_generation[\"no scores\"])), w).squeeze(-1))\n",
        "      current_generation[\"true scores\"] += list(zip(current_generation[\"no scores\"], new_scores))\n",
        "      current_generation[\"no scores\"] = []\n",
        "      current_generation[\"true scores\"] = sorted(current_generation[\"true scores\"], key = lambda x : x[1], reverse = True)[:crossover_cutoff]\n",
        "    else:\n",
        "      # If a model is given, score estimations are done using the model for all layouts which currently have no scores at all\n",
        "      # Notice, w has the user provided weights to place on each metric and the weighted sums are taken here\n",
        "      new_estimated_scores = list(np.matmul(model(np.array(current_generation[\"no scores\"])), w).squeeze(-1))\n",
        "      current_generation[\"estimated scores\"] += list(zip(current_generation[\"no scores\"], new_estimated_scores))\n",
        "      current_generation[\"no scores\"] = []\n",
        "      current_generation[\"estimated scores\"] = sorted(current_generation[\"estimated scores\"], key = lambda x : x[1], reverse = True)\n",
        "\n",
        "      # The evaluation rate controls how many of the top layouts with only estimated scores recieve a full evaluation\n",
        "      # The crossover cutoff controls how many of the top layouts given true evaluations are used in the crossover/mutation phase\n",
        "      # Since layouts past this cutoff will no longer affect the algorithm, they are deleted at this stage\n",
        "      layouts_to_evaluate = [a for a, s in current_generation[\"estimated scores\"][:evaluation_rate]]\n",
        "      new_scores = true_evaluation(layouts_to_evaluate, metric_weights, symbols)\n",
        "      current_generation[\"true scores\"] += list(zip(layouts_to_evaluate, new_scores))\n",
        "      current_generation[\"true scores\"] = sorted(current_generation[\"true scores\"], key = lambda x : x[1], reverse = True)[:crossover_cutoff]\n",
        "      del current_generation[\"estimated scores\"][:evaluation_rate]\n",
        "\n",
        "    if delete_duplicates:\n",
        "      for i in range(len(current_generation[\"true scores\"]) - 1, 0, -1):\n",
        "        if current_generation[\"true scores\"][i - 1][0] == current_generation[\"true scores\"][i][0]:\n",
        "          del current_generation[\"true scores\"][i]\n",
        "\n",
        "    ## COPIES FROM CURRENT GENERATION ADDED TO NEXT GENERATION ##\n",
        "\n",
        "    # All top layouts with true scores from the current generation are carried over to the next\n",
        "    # The copy rate controls the total number of layouts carried over to the next generation\n",
        "    # The rest of this quota is filled by the top layouts with high estimated scores\n",
        "    next_generation = {\"no scores\": [], \"estimated scores\": current_generation[\"estimated scores\"][:copy_rate - len(current_generation[\"true scores\"])], \"true scores\": current_generation[\"true scores\"]}\n",
        "\n",
        "    # ADDITIONAL RANDOM LAYOUTS ADDED TO NEXT GENERATION ##\n",
        "\n",
        "    # The random rate controls the number of random layouts added to the next generation\n",
        "    a = [i for i in range(n)]\n",
        "    for i in range(random_rate):\n",
        "      random.shuffle(a)\n",
        "      next_generation[\"no scores\"].append(copy.deepcopy(a))\n",
        "\n",
        "    ## CROSSOVER/MUTATED LAYOUTS FROM CURRENT GENERATION ADDED TO NEXT GENERATION ##\n",
        "\n",
        "    # The pop variable controls the constant population of each generation\n",
        "    # The remaining quota is filled at this point by crossing over two layouts from the current generation and mutating the result\n",
        "    for i in range(pop - random_rate - len(next_generation[\"estimated scores\"]) - len(next_generation[\"true scores\"])):\n",
        "      # MKLOGA code shows that they picked the crossovers using a beta distribution with these parameters\n",
        "      index_a , index_b = np.floor(min(crossover_cutoff, len(current_generation[\"true scores\"]))*np.random.beta(a = 0.5, b = 2, size = 2)).astype(int)\n",
        "\n",
        "      a, b = current_generation[\"true scores\"][index_a][0], current_generation[\"true scores\"][index_b][0]\n",
        "      next_generation[\"no scores\"].append(copy.deepcopy(mutate(crossover(a, b, n), mutation_rate, n)))\n",
        "\n",
        "    current_generation = copy.deepcopy(next_generation)\n",
        "\n",
        "  return current_generation[\"true scores\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AiU2fePTrhdL"
      },
      "outputs": [],
      "source": [
        "# Creates our Neural Network and its Optimizer\n",
        "# For the sake of efficiency, the network assumes you have already created the one-hot encodings of the layouts\n",
        "architecture = [\n",
        "  CustomLayer(900),\n",
        "  CustomLayer(900),\n",
        "  CustomLayer(900),\n",
        "  CustomLayer(900),\n",
        "  CustomLayer(900),\n",
        "  CustomLayer(900),\n",
        "  CustomLayer(900),\n",
        "  CustomLayer(900),\n",
        "  layers.Dense(5)\n",
        "]\n",
        "\n",
        "network = models.Sequential(architecture)\n",
        "network.compile(loss=\"mse\")\n",
        "network.build(input_shape = (None, 900))\n",
        "\n",
        "# These are the means (offsets) and mean absolute deviations (scalars) of each of the five metrics\n",
        "# These were calculated from a set of 10,000 uniformly random layouts\n",
        "scalars = np.array([2.37272293, 1.77984022, 1.84450506, 2.34851446, 2.97247169])\n",
        "offsets = np.array([10.53548093, 10.47626445,  3.99833419, 17.61765303, 35.32753762])\n",
        "\n",
        "L1 = layers.CategoryEncoding(num_tokens = 30, output_mode = \"one_hot\")\n",
        "L2 = layers.Flatten()\n",
        "\n",
        "def model(layouts):\n",
        "  return scalars*network(L2(L1(layouts))) + offsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4rlsVRMOum1l"
      },
      "outputs": [],
      "source": [
        "# Running this will require having your Google Drive attached!\n",
        "# Loads the network pretrained weights\n",
        "save_path = '/content/drive/My Drive/colab_data/'\n",
        "with open(os.path.join(save_path, 'eight_hidden_layer_network_weights.pkl'), 'rb') as f:\n",
        "  network.set_weights(pickle.load(f))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMhklPyFVK2-",
        "outputId": "7330d67b-59f8-411b-c2e7-e8bd98648fa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "# The tests we ran on the Genetic Algorithm using a A100 GPU\n",
        "# The random seed will often be set at the top of each cell to ensure you can reproduce the results found in our paper\n",
        "# These seed values were themselves chosen randomly with no cherry picking\n",
        "\n",
        "## Test 1 weights ##\n",
        "# metric_weights = {\"sfb\": -1.5, \"sfs\": -0.7, \"lsb\": -0.8, \"alt\": 0.2, \"rolls\": 0.3}\n",
        "\n",
        "# mode = 0\n",
        "# random.seed(795)\n",
        "\n",
        "# mode = 1\n",
        "# random.seed(345)\n",
        "\n",
        "# mode = 2\n",
        "# random.seed(679)\n",
        "\n",
        "\n",
        "\n",
        "## Test 2 weights ##\n",
        "# metric_weights = {\"sfb\": -1.0, \"sfs\": -0.2, \"lsb\": -0.2, \"alt\": 0.5, \"rolls\": 0.5}\n",
        "\n",
        "# mode = 0\n",
        "# random.seed(268)\n",
        "\n",
        "# mode = 1\n",
        "# random.seed(837)\n",
        "\n",
        "# mode = 2\n",
        "#random.seed(132)\n",
        "\n",
        "worse_time = 0.0\n",
        "average_time = 0.0\n",
        "best_time = float('infinity')\n",
        "\n",
        "best_layout = []\n",
        "worse_score = float('infinity')\n",
        "average_score = 0.0\n",
        "best_score = -float('infinity')\n",
        "\n",
        "# Runs the Genetic Algorithm ten times with this same set of weights and mode, and reports back the worse, average, and best scores/runtimes\n",
        "for i in range(10):\n",
        "  print(i)\n",
        "  start_time = time.process_time()\n",
        "  layout, score = evolve(5000, 30, 1000, 250, 250, 100, 5, True, mode, model, metric_weights, symbols)\n",
        "  end_time = time.process_time()\n",
        "  duration = end_time - start_time\n",
        "\n",
        "  if mode == 2:\n",
        "    score = true_evaluation([layout], metric_weights, symbols)[0]\n",
        "\n",
        "  worse_time = max(worse_time, duration)\n",
        "  average_time += duration/10.0\n",
        "  best_time = min(best_time, duration)\n",
        "\n",
        "  if score > best_score:\n",
        "    best_layout = copy.deepcopy(layout)\n",
        "\n",
        "  worse_score = min(worse_score, score)\n",
        "  average_score += score/10.0\n",
        "  best_score = max(best_score, score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E32iyWvBxH0Z",
        "outputId": "37050c3c-904e-4181-cd74-cea0658b7fb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "# Random Search tests we ran on a A100 GPU\n",
        "\n",
        "# Test 1 Random Search\n",
        "# metric_weights = {\"sfb\": -1.5, \"sfs\": -0.7, \"lsb\": -0.8, \"alt\": 0.2, \"rolls\": 0.3}\n",
        "# random.seed(223)\n",
        "\n",
        "\n",
        "\n",
        "# Test 2 Random Search\n",
        "# metric_weights = {\"sfb\": -1.0, \"sfs\": -0.2, \"lsb\": -0.2, \"alt\": 0.5, \"rolls\": 0.5}\n",
        "# random.seed(869)\n",
        "\n",
        "worse_time = 0.0\n",
        "average_time = 0.0\n",
        "best_time = float('infinity')\n",
        "\n",
        "worse_score = float('infinity')\n",
        "average_score = 0.0\n",
        "best_score = -float('infinity')\n",
        "\n",
        "# Runs the Random Search ten times with this same set of weights and mode, and reports back the worse, average, and best scores/runtimes\n",
        "for i in range(10):\n",
        "  print(i)\n",
        "  start_time = time.process_time()\n",
        "  layouts = [[i for i in range(30)] for j in range(150000)]\n",
        "  for a in layouts:\n",
        "    random.shuffle(a)\n",
        "  scores = true_evaluation(layouts, metric_weights, symbols)\n",
        "  score = max(scores)\n",
        "  end_time = time.process_time()\n",
        "  duration = end_time - start_time\n",
        "\n",
        "  worse_time = max(worse_time, duration)\n",
        "  average_time += duration/10.0\n",
        "  best_time = min(best_time, duration)\n",
        "\n",
        "  worse_score = min(worse_score, score)\n",
        "  average_score += score/10.0\n",
        "  best_score = max(best_score, score)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
